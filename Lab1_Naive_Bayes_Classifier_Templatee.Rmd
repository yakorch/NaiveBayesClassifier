---
editor_options:
  markdown:
    wrap: 72
output:
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Probability and Statistics

# Lab Assignment 1: Naive Bayes Classifier

### *Yaroslav Korch, Yaroslav Tkachuk*

## Introduction

During the past three weeks, you learned a couple of essential notions
and theorems, and one of the most important among them is the *Bayes
theorem*.

One of its applications is **Naive Bayes classifier**, which is a
probabilistic classifier whose aim is to determine which class some
observation probably belongs to by using the Bayes formula:
$$\mathsf{P}(\mathrm{class}\mid \mathrm{observation})=\frac{\mathsf{P}(\mathrm{observation}\mid\mathrm{class})\mathsf{P}(\mathrm{class})}{\mathsf{P}(\mathrm{observation})}$$

Under the strong independence assumption, one can calculate
$\mathsf{P}(\mathrm{observation} \mid \mathrm{class})$ as
$$\mathsf{P}(\mathrm{observation}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i), \qquad \mathsf{P}(\mathrm{observation} \mid \mathrm{class}) = \prod_{i=1}^{n} \mathsf{P}(\mathrm{feature}_i \mid \mathrm{class}),$$
where $n$ is the total number of features describing a given
observation. Thus, $\mathsf{P}(\mathrm{class}|\mathrm{observation})$ now
can be calculated as

$$\mathsf{P}(\mathrm{class} \mid \mathrm{\mathrm{observation}}) = \mathsf{P}(\mathrm{class})\times \prod_{i=1}^{n}\frac{\mathsf{P}(\mathrm{feature}_i\mid \mathrm{class})}{\mathsf{P}(\mathrm{feature}_i)}\tag{1}$$

All the terms on the right-hand side can be estimated from the data as
respective relative frequencies;\
see [this
site](https://monkeylearn.com/blog/practical-explanation-naive-bayes-classifier/)
for more detailed explanations.

## Data description

### 9-th team = 4 (mod 5)

-   **4 - spam** This last data set contains SMS messages classified as
    spam or non-spam (ham in the data set). The task is to determine
    whether a given message is spam or non-spam.

## *train.csv* is used to build a bag-of-words, while *test.csv* - to see how well the Bayes Classifier works


```{r Including packages}
# here goes a list of recommended libraries,
# though you may install other ones if they are needed
library(tidytext)
library(readr)
library(dplyr)
library(ggplot2)
library(wordcloud)
```

## Instructions

-   The first step is data pre-processing, which includes removing
    punctuation marks and stop words

-   represent each message as a bag-of-words

-   using the training set, calculate all the conditional probabilities
    in formula (1)

-   use those to predict classes for messages in the test set

-   evaluate effectiveness of the classifier by calculating the
    corresponding metrics

-   shortly summarize your work

-   do not forget to submit both the (compiled) Rmd source file and the .html
    output

## Linking all needed files and parsing stop words:

```{r Adding stop words}
test_path <- "data/4-spam/test.csv"
train_path <- "data/4-spam/train.csv"

stop_words <- read_file("stop_words.txt")
splitted_stop_words <- strsplit(stop_words, split="[\r\n|\n]")
splitted_stop_words <- splitted_stop_words[[1]]
```
## Reading these files:
```{r Reading the data}
train <-  read.csv(file = train_path, stringsAsFactors = FALSE)
test <-  read.csv(file = test_path, stringsAsFactors = FALSE)
```
##### Reforming the data into practical representation. Splitting each Message into list of words, and then combining all of them to one bag-of-words (df). Then, separating spam and non-spam parts of train df

```{r Cleaning the data}
# note the power functional features of R bring us! 
tidy_text <- unnest_tokens(train, output = 'word', input ='Message') %>%
             filter(!word %in% splitted_stop_words)

df <- tidy_text %>% count(word, sort=TRUE)

df_with_categories <- tidy_text %>% count(Category, word, sort=TRUE)
spam_df <- df_with_categories %>% filter(Category=="spam")
non_spam_df <- df_with_categories %>% filter(Category=="ham")
```

### Data visualization

Each time you work with some data, you need to understand it before you
start processing it. R has very powerful tools to make nice plots and
visualization. Show what are the most common words for negative and
positive examples as a histogram, word cloud etc. Be creative!


### TODO - Visualize the most frequent words

# Classifier implementation

Splitting the test data in two parts for easier access to true positives, false positives ...

Calculating the ratio of spam or non-spam in a given training data

```{r Helping values}
spam_test_df = test %>% filter(Category=="spam") %>% count(Category, Message, result=1)
ham_test_df = test %>% filter(Category=="ham") %>% count(Category, Message, result=1)
is_spam = nrow(train %>% filter(Category=="spam"))/nrow(train)
is_not_spam = 1 - is_spam
```





**Method fit** - tests how well the Classifier works (runs the test data and records the results)

**Fields X_test and y_test** serve to save these tests. They have one additional column - for the result. The result is 1 if a message was identified correctly. For test dataframe with spam message the correct prediction is 0 because 0 corresponds to spam, while 1 - to non-spam. This is why in test dataframe with non-spam the correct prediction is 1.

**Method predict** - predicts a message (spam or not). Input - a table 3x1 (Category, Message, result).

**Method score** - Builds plots for better understanding of program's effectiveness.

```{r Class Definition}
naiveBayes <- setRefClass("naiveBayes",

        # X_test - for spam, y_test - for ham (non-spam)
       fields = list(X_test="data.frame", y_test="data.frame"),

       methods = list(
                    fit = function()
                    {
                      for (row in 1:nrow(spam_test_df)){
                        val = predict(spam_test_df[row, -4])
                        if (val == 1){
                          spam_test_df[row, "result"] = 0
                        }
                      }
                      for (row in 1:nrow(ham_test_df)){
                        val = predict(ham_test_df[row, -4])
                        if (val == 0){
                            ham_test_df[row, "result"] = 0
                        }
                      }
                        X_test <<- spam_test_df
                        y_test <<- ham_test_df
                    },


                    # returns prediction for a single message
                    # 0 - spam, 1 - non-spam
                    predict = function(message)
                    {
                         #TODO: split message into words, for each list calc the probability, return the highest
                      words <- unnest_tokens(message, output = 'word', input = 'Message')
                      dfs <- list(spam_df, non_spam_df)
                      res <- list(0, 0)
                      for (ind in 1:2){
                        curr_df <- dfs[[ind]]
                        sum <- 1
                        for (row in 1:nrow(words)) {
                            sum <- sum * calc_probability(words[row, "word"], curr_df)
                        }
                        if (ind == 1){
                          res[[1]] = sum * is_spam
                        }
                        else{
                          res[[2]] = sum * is_not_spam
                        }
                      }
                      if (res[[1]] > res[[2]]){
                        return(0)
                      }
                      return(1)
                    },
                    predict_from_string= function(string){
                        temp_df = data.frame(Category='unknown', Message=string, result=1)
                        return(predict(temp_df))
                    },

                    # calculates the probability for a single word
                    calc_probability = function (word, cur_df){
                        pos <- which(cur_df["word"] == word)
                        divisor <- nrow(cur_df) + nrow(df)
                        if (length(pos) == 0){
                          return(1/divisor)
                        }
                        else {
                          occurences = cur_df["n"][pos, ]
                          return ((1+occurences)/divisor)
                        }
                    },

                    # score you test set so to get the understanding how well you model
                    # works.
                    # look at f1 score or precision and recall
                    # visualize them
                    # try how well your model generalizes to real world data!
                    score = function()
                      {
                      #X_Test - identified as spam
                      #y_test - identified as ham
                      spam_true <- X_test[X_test$result == TRUE, ]
                      spam_true_amount <- nrow(spam_true)
                      
                      ham_false <- y_test[y_test$result == FALSE, ]
                      ham_false_amount <- nrow(ham_false)
                      
                      ham_true_amount = nrow(y_test) - nrow(ham_false)
                      spam_false_amount = nrow(X_test) - nrow(spam_true)
                      
                      Precision <- spam_true_amount / (spam_true_amount + 
                                                         ham_false_amount)
                      
                      Recall <- spam_true_amount / nrow(X_test)
                      
                      F1 <- 2 * (Precision * Recall / (Precision + Recall))
                      
                      Precision_Ham  <- ham_true_amount / (ham_true_amount + spam_false_amount)
                      
                      Recall_Ham <- ham_true_amount / nrow(y_test)
                      
                      F1_Ham <- 2 * (Precision_Ham * Recall_Ham) / (Precision_Ham + Recall_Ham)
                      
                      Accuracy <- (spam_true_amount + ham_true_amount) / (nrow(X_test) + nrow(y_test))
                      
                      numbers_of_guesses = 
                        as.matrix(data.frame(predicted = c(spam_true_amount, ham_true_amount), unpredicted = c(spam_false_amount, ham_false_amount)))
                      par(mfrow = c(1, 2))
                      
                      barplot(numbers_of_guesses,
                              main = "Predicted messages",
                              xlab = "Predictions",
                              ylab = "Number of messages",
                              names.arg = c("Correct Predictions", "Wrong predictions"),
                              col = c("#1b98e0", "#353436"),
                              horiz = FALSE,
                              beside = TRUE)
                      legend("topright",
                             legend = c("Spam", "Ham"),
                             fill = c("#1b98e0", "#353436"))
                      
                      
                      metrics <- as.matrix(data.frame(P = c(Precision, Precision_Ham), R = c(Recall, Recall_Ham), f = c(F1, F1_Ham), A = c(Accuracy, 0)))
                      barplot(
                        metrics,
                        beside = TRUE,
                        main = "Predictions acuraccy",
                        xlab = "metrics",
                        ylab = "values",
                        ylim = c(0, 1),
                        names.arg = c("Precision", "Recall", "F1 score", "Accuracy"),
                        col = c("#1b98e0", "#353436", "#1b98e0", "#353436", "#1b98e0", "#353436", "orange"),
                        horiz = FALSE)
                      
                      legend("bottomright",              
                          legend = c("Spam", "Ham", "Accuracy"),
                          fill = c("#1b98e0", "#353436", "orange"))
                    },
                    
                    frequentWords = function()
                    {
                      par(mfrow = c(1, 3))
                     
                      wordcloud(words = spam_df$word, freq = spam_df$n, min.freq = 5, max.words=40, random.order=FALSE, colors = 'red', use.r.layout=FALSE)
                      plot.new()
                      legend("top", legend = c("Spam", "Ham"), fill = c("red", "green"), title="Frequent words")
                      wordcloud(words = non_spam_df$word, freq = non_spam_df$n, min.freq = 1, max.words=40, random.order=FALSE, colors = 'green', use.r.layout=FALSE)
                      
                      
                      
                    }
                      
))

model = naiveBayes()


```

## Measure effectiveness of your classifier

- After testing the given data, results show 98% accuracy out of all data, while accuracy for separate parts differ.
- Precision for spam messages (ratio of truly spam messages out of identified as spam ) = 138/(138+8) = 94.5 %
- Precision for non-spam messages (ratio of truly non-spam messages out of identified as non-spam) 1053/(1053 + 14) = 98.7%
- Recall for spam messages -- 90.8%
- Recall for non-spam messages -- 99.25%
- F1 score for spam messages -- 92.62%
- F1 score for non-spam messages -- 98.97%


```{r Visualization}
model$fit()
model$score()
model$frequentWords()
```

## To test the Bayes Classifier on real-world data...
use the predict_from_string() method. Better use longer messages. Some examples would be:
```{r}
model$predict_from_string("You have won a mobile phone. To get a free phone, call us at humber 2837123792!!!")
model$predict_from_string("Hey mate, how is your life going?")
```
## Conclusions


- The implemented method is Naive Bayes Classifier. We used it to predict the Category of a message. Choosing the probable category means calculating the probability of message belonging to each category and then picking the highest one. Since it is very unlikely for the message to repeat in train data, we divide the message into clean words (lowercase + no punctuation marks). Then probability for sentence = product of probabilities of each word. The bag-of-words helps quickly find matches in the training data.

- The method doesn't process the meaning of a sentence, and just counts words.  The non-spam message might include words that often appear in spam. Then, the Classifier will mark it a 'spam'. It works vice versa too. To improve this method, words can be stored as phrases. Despite that, the method is easy to understand and quite effective to filter spam messages. As stats show, only 6 out 1061 non-spam were wrongly identified as spam.